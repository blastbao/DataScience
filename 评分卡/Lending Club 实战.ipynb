{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lending Club，P2P平台，公司位于美国旧金山。2014年12月12日开始在纽交所挂牌交易，代码LC。目前总市值54亿美元。\n",
    "\n",
    "所用数据是 LoanStats_2016Q4.csv 和LoanStats_2017Q1.csv ，在 LoanStats_2016Q4.csv 上训练模型和验证模型，在LoanStats_2017Q1.csv上加载模型用来测试模型表现。\n",
    "\n",
    "所用模型是LogisticRegression 和 XGBClassifier，默认参数未调参\n",
    "\n",
    "数据来源：https://www.lendingclub.com/info/download-data.action\n",
    "特征变量解释：http://www.docin.com/p-635342290.html\n",
    "目标变量解释：http://www.doc88.com/p-5089631302589.html\n",
    "\n",
    "# Step 1: 数据加载\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2902: DtypeWarning: Columns (0,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "data=pd.read_csv('LoanStats_2016Q4.csv',skiprows=1)\n",
    "data.head()\n",
    "data0=data\n",
    "#import missingno\n",
    "#missingno.matrix(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们发现共103548个样本，145个特征。\n",
    "\n",
    "缺失值可视化发现，很多特征含有缺失值。\n",
    "\n",
    "# Step 2: 数据预处理与特征过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sec_app_mths_since_last_major_derog           1.000000\n",
       "member_id                                     1.000000\n",
       "url                                           1.000000\n",
       "revol_bal_joint                               1.000000\n",
       "sec_app_earliest_cr_line                      1.000000\n",
       "sec_app_inq_last_6mths                        1.000000\n",
       "sec_app_mort_acc                              1.000000\n",
       "sec_app_open_acc                              1.000000\n",
       "sec_app_revol_util                            1.000000\n",
       "sec_app_open_act_il                           1.000000\n",
       "sec_app_num_rev_accts                         1.000000\n",
       "sec_app_chargeoff_within_12_mths              1.000000\n",
       "sec_app_collections_12_mths_ex_med            1.000000\n",
       "desc                                          0.999990\n",
       "id                                            0.999981\n",
       "settlement_percentage                         0.997943\n",
       "settlement_term                               0.997943\n",
       "settlement_date                               0.997943\n",
       "debt_settlement_flag_date                     0.997943\n",
       "settlement_status                             0.997943\n",
       "settlement_amount                             0.997943\n",
       "orig_projected_additional_accrued_interest    0.995934\n",
       "hardship_dpd                                  0.995471\n",
       "deferral_term                                 0.995471\n",
       "hardship_last_payment_amount                  0.995471\n",
       "hardship_payoff_balance_amount                0.995471\n",
       "hardship_loan_status                          0.995471\n",
       "hardship_amount                               0.995471\n",
       "hardship_length                               0.995471\n",
       "hardship_end_date                             0.995471\n",
       "                                                ...   \n",
       "num_rev_tl_bal_gt_0                           0.000019\n",
       "num_rev_accts                                 0.000019\n",
       "num_op_rev_tl                                 0.000019\n",
       "num_accts_ever_120_pd                         0.000019\n",
       "num_actv_bc_tl                                0.000019\n",
       "num_actv_rev_tl                               0.000019\n",
       "num_bc_sats                                   0.000019\n",
       "inq_fi                                        0.000019\n",
       "max_bal_bc                                    0.000019\n",
       "last_pymnt_amnt                               0.000019\n",
       "tot_coll_amt                                  0.000019\n",
       "num_bc_tl                                     0.000019\n",
       "collections_12_mths_ex_med                    0.000019\n",
       "tax_liens                                     0.000019\n",
       "policy_code                                   0.000019\n",
       "application_type                              0.000019\n",
       "pub_rec_bankruptcies                          0.000019\n",
       "pct_tl_nvr_dlq                                0.000019\n",
       "acc_now_delinq                                0.000019\n",
       "tot_cur_bal                                   0.000019\n",
       "open_rv_24m                                   0.000019\n",
       "open_acc_6m                                   0.000019\n",
       "open_act_il                                   0.000019\n",
       "open_il_12m                                   0.000019\n",
       "open_il_24m                                   0.000019\n",
       "num_tl_op_past_12m                            0.000019\n",
       "total_bal_il                                  0.000019\n",
       "num_tl_90g_dpd_24m                            0.000019\n",
       "open_rv_12m                                   0.000019\n",
       "total_cu_tl                                   0.000019\n",
       "Length: 145, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_null=data.isnull().sum(axis=0).sort_values(ascending=False)/float(len(data))\n",
    "check_null[check_null>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预处理：删除缺失比例0.5以上的变量、常数变量、检查有没有重复变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103548, 102)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.dropna(thresh=len(data)*0.5,axis=1)\n",
    "data=data.loc[:,data.apply(pd.Series.nunique)!=1]\n",
    "len(set(list(data.columns)))==data.shape[1]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再继续看看下数据集形状，发现特征从145变成了102\n",
    "\n",
    "数据集中很多特征是关于投资人的数据，与建模无关，所以我需要过滤变量；同时为了便于大家理解，我把特征重命名为中文。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'loan_amnt','funded_amnt','funded_amnt_inv','term','int_rate','installment','grade','sub_grade','emp_title','emp_length','home_ownership','annual_inc','verification_status','issue_d','loan_status','pymnt_plan','purpose','title','zip_code','addr_state','dti','delinq_2yrs','earliest_cr_line','inq_last_6mths','mths_since_last_delinq','open_acc','pub_rec','revol_bal','revol_util','total_acc','initial_list_status','out_prncp','out_prncp_inv','total_pymnt','total_pymnt_inv','total_rec_prncp','total_rec_int','total_rec_late_fee','recoveries','collection_recovery_fee','last_pymnt_d','last_pymnt_amnt','next_pymnt_d','last_credit_pull_d','collections_12_mths_ex_med','application_type','acc_now_delinq','tot_coll_amt','tot_cur_bal','open_acc_6m','open_act_il','open_il_12m','open_il_24m','mths_since_rcnt_il','total_bal_il','il_util','open_rv_12m','open_rv_24m','max_bal_bc','all_util','total_rev_hi_lim','inq_fi','total_cu_tl','inq_last_12m','acc_open_past_24mths','avg_cur_bal','bc_open_to_buy','bc_util','chargeoff_within_12_mths','delinq_amnt','mo_sin_old_il_acct','mo_sin_old_rev_tl_op','mo_sin_rcnt_rev_tl_op','mo_sin_rcnt_tl','mort_acc','mths_since_recent_bc','mths_since_recent_inq','num_accts_ever_120_pd','num_actv_bc_tl','num_actv_rev_tl','num_bc_sats','num_bc_tl','num_il_tl','num_op_rev_tl','num_rev_accts','num_rev_tl_bal_gt_0','num_sats','num_tl_120dpd_2m','num_tl_30dpd','num_tl_90g_dpd_24m','num_tl_op_past_12m','pct_tl_nvr_dlq','percent_bc_gt_75','pub_rec_bankruptcies','tax_liens','tot_hi_cred_lim','total_bal_ex_mort','total_bc_limit','total_il_high_credit_limit','hardship_flag','disbursement_method','debt_settlement_flag'\n"
     ]
    }
   ],
   "source": [
    "print(','.join([\"'{}'\".format(s) for s in data.columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col=['loan_amnt','term','int_rate','installment','grade','sub_grade','emp_length','home_ownership','annual_inc','verification_status',\\\n",
    "     'issue_d','loan_status','purpose','addr_state','dti','delinq_2yrs','earliest_cr_line','inq_last_6mths','open_acc','pub_rec','revol_bal',\\\n",
    "     'revol_util','total_acc','acc_now_delinq','delinq_amnt','pub_rec_bankruptcies','tax_liens']\n",
    "data=data[col]\n",
    "new_col={\n",
    "'loan_amnt':'贷款金额',\n",
    "'term':'贷款期限',\n",
    "'int_rate':'利率',\n",
    "'installment':'每月还款金额',\n",
    "'grade':'贷款等级',\n",
    "'sub_grade':'基础等级',\n",
    "'emp_length':'工作年限',#（0：少于1年，10：10年及以上）\n",
    "'home_ownership':'房屋所有权',#(出租、自有、按揭、其他)\n",
    "'annual_inc':'年收入',\n",
    "'verification_status':'收入是否由LC验证',\n",
    "'issue_d':'放款日期',\n",
    "'loan_status':'target',\n",
    "'purpose':'贷款目的',\n",
    "'addr_state':'申请人所在洲',\n",
    "'dti':'月负债比',\n",
    "'delinq_2yrs':'过去两年借款人逾期30天以上的数字',\n",
    "'earliest_cr_line':'信用报告最早日期',\n",
    "'inq_last_6mths':'过去6个月内被查询次数',\n",
    "'open_acc':'未还清贷款额度',\n",
    "'pub_rec':'摧毁公共记录的数量',\n",
    "'revol_bal':'总贷款金额',\n",
    "'revol_util':'额度循环使用率',\n",
    "'total_acc':'总贷款笔数',\n",
    "'acc_now_delinq':'拖欠的账户数量',\n",
    "'delinq_amnt':'拖欠的逾期款项',\n",
    "'pub_rec_bankruptcies':'公开记录破产的数量',\n",
    "'tax_liens':'留置税数量'}\n",
    "\n",
    "data=data.rename(columns=new_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "贷款金额 103548\n",
      "贷款期限 103548\n",
      "利率 103548\n",
      "每月还款金额 103548\n",
      "贷款等级 103548\n",
      "基础等级 103548\n",
      "工作年限 103548\n",
      "房屋所有权 103548\n",
      "年收入 103548\n",
      "收入是否由LC验证 103548\n",
      "放款日期 103548\n",
      "target 103548\n",
      "贷款目的 103548\n",
      "申请人所在洲 103548\n",
      "月负债比 103548\n",
      "过去两年借款人逾期30天以上的数字 103548\n",
      "信用报告最早日期 103548\n",
      "过去6个月内被查询次数 103548\n",
      "未还清贷款额度 103548\n",
      "摧毁公共记录的数量 103548\n",
      "总贷款金额 103548\n",
      "额度循环使用率 103548\n",
      "总贷款笔数 103548\n",
      "拖欠的账户数量 103548\n",
      "拖欠的逾期款项 103548\n",
      "公开记录破产的数量 103548\n",
      "留置税数量 103548\n"
     ]
    }
   ],
   "source": [
    "for c in data.columns:\n",
    "    print(c,data[c].dropna().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4ba2be438781>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mreportgen\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mrpt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrpt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAnalysisReport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'club report'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\reportgen\\analysis.py\u001b[0m in \u001b[0;36mAnalysisReport\u001b[1;34m(data, filename, var_list)\u001b[0m\n\u001b[0;32m    270\u001b[0m     '''\n\u001b[0;32m    271\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvar_list\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[0mvar_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvar_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[0mslides_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\reportgen\\analysis.py\u001b[0m in \u001b[0;36mvar_detection\u001b[1;34m(data, combine)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[0mvar_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mresult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mvar_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\reportgen\\analysis.py\u001b[0m in \u001b[0;36mdtype_detection\u001b[1;34m(columns, data, category_detection)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mcategories\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;31m# 纠正误分的数据类型。如将1.0，2.0，3.0都修正为1，2，3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcategory_detection\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m15\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[0;32m   3297\u001b[0m         \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3298\u001b[0m         new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[1;32m-> 3299\u001b[1;33m                                      **kwargs)\n\u001b[0m\u001b[0;32m   3300\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m   3222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3224\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'astype'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3226\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m   3089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3090\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mgr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3091\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3092\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3093\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[0;32m    469\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'raise'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[1;32m--> 471\u001b[1;33m                             **kwargs)\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_astype\u001b[1;34m(self, dtype, copy, errors, values, klass, mgr, **kwargs)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             raise ValueError('Cannot convert non-finite values (NA or inf) to '\n\u001b[0m\u001b[0;32m    621\u001b[0m                              'integer')\n\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "from imp import reload\n",
    "import reportgen as rpt\n",
    "reload(rpt)\n",
    "rpt.AnalysisReport(data,'club report')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: 特征抽象与可视化\n",
    "\n",
    "我先把变量分为连续变量与分类变量，发现有11个连续变量，15个分类变量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(continuous_var)\n",
    "len(categorical_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col='target'\n",
    "print(data[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发现目标变量有点乱，没关系。\n",
    "\n",
    "特征抽象：把目标变量各水平转为我们所需要的0、1形式。\n",
    "\n",
    "处理后发现正常客户17731，违约客户6816\n",
    "\n",
    "特征中有时间变量：信用报告最早日期、放款日期。\n",
    "\n",
    "\n",
    "\n",
    "我们知道美国的征信数据是比较完善的，那我想知道会不会开启“信用报告天赋”越早，表现越好呢？\n",
    "\n",
    "这里稍微做了个特征衍生，创建了新变量days，含义是放款时，客户拥有信用报告的天数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['t1_new']=data['信用报告最早日期'].apply(lambda x:datetime.datetime.strptime(x,'%Y-%m'))\n",
    "data['t2_new']=data['放款日期'].apply(lambda x:datetime.datetime.strptime(x,'%Y-%m'))\n",
    "data['days']=daa[['t1_new','t2_new']].apply(lambda x:(x[1]-x[0]).days,axis=1)\n",
    "data['days'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在做过分类变量水平合并和删除严重不平衡的分类变量后，接下来就是可视化了：让我们看一下各变量的分布以及与目标变量的关系吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有一句话叫：老板看不懂代码，但能看得懂图。get可视化技能很重要哦！\n",
    "\n",
    "\n",
    "\n",
    "对于以上图片相信大家都能看懂，我就不赘述了，接下来再次预览数据，还剩下22个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['string_var'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: 数据补缺\n",
    "\n",
    "\n",
    "\n",
    "我们先看一下处理后的数据缺失情况吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.isnull().sum(axis=0).sort_values(ascending=False)/float(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里，我把连续变量用随机抽样补缺，分类变量用众数补缺，同时统一字符变量为大写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in string_var:\n",
    "    data[col]=data[col].apply(lambda x:str(x).upper)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: 卡方分箱，计算WOE和IV值\n",
    "\n",
    "\n",
    "\n",
    "为了创建申请评分卡，我们不用One-hot、不用归一化，而是选择卡方分箱和WOE编码。\n",
    "\n",
    "这里先解释下卡方分箱、WOE和IV的概念：\n",
    "\n",
    "![](641.webp)\n",
    "![](640.webp)\n",
    "\n",
    "\n",
    "卡方分箱和WOE计算过程较为繁琐，这里不再赘述。最终保存如下数据：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "f=open('var_WOE.pkl','wb')\n",
    "pickle.dump(var_WOE,f)\n",
    "f.close()\n",
    "\n",
    "f=open('var_IV.pkl','wb')\n",
    "pickle.dump(var_IV,f)\n",
    "f.close()\n",
    "\n",
    "f=open('var_cutoff.pkl','wb')\n",
    "pickle.dump(var_cutoff,f)\n",
    "f.close()\n",
    "\n",
    "f=open('encoded_features.pkl','wb')\n",
    "pickle.dump(encoded_features,f)\n",
    "f.close()\n",
    "\n",
    "f=open('merged_features.pkl','wb')\n",
    "pickle.dump(merged_features,f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然分箱前只有22个特征，但还是要筛选变量的，经过IV筛选和相关系数筛选后，\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-f05677cd3877>, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-f05677cd3877>\"\u001b[1;36m, line \u001b[1;32m24\u001b[0m\n\u001b[1;33m    else:\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'''单变量分析，找出IV大于0.02的变量'''\n",
    "iv_threshould=0.02\n",
    "varByIV=[k for k,v in var_IV.items() if v > iv_threshoyld]\n",
    "print('剩余%d个变量'%len(varByIV))\n",
    "print(varByIV)\n",
    "'''多变量分析，保留相关性大于阈值0.6的变量'''\n",
    "var_IV_selected={k:var_IV[k] for k in varByIV}\n",
    "var_IV_sorted=sorted(var_IV_selected.items())\n",
    "var_IV_sorted=[i[0] for i in var_IV_sorted] #IV排序的列名称\n",
    "removed_var=[] #两两相关性判断，被删除的变量\n",
    "roh_thresould = 0.6\n",
    "\n",
    "for i in range(len(var_IV_sorted)-1):\n",
    "    if var_IV_sorted[i] not in removed_var:\n",
    "        x1=var_IV_sorted[i]+'_WOE'\n",
    "        for j in range(i+1,len(var_IV_sorted)):\n",
    "            if var_IV_sorted[j] not in removed_var:\n",
    "                x2=var_IV_sorted[j] + '_WOE'\n",
    "                roh=np.corrcoef([data[x1],data[x2]])[0,1]\n",
    "                if abs(roh) >= roh_thresould:\n",
    "                    print('{} 和 {} 的相关系数是 {}'.format(x1,x2,str(roh)))\n",
    "                    if var_IV[var_IV_sorted[i]] > var_IV[var_IV_sorted[j]]: #删除IV值较小的变量\n",
    "                        removed_var.append(var_IV_sorted[j])\n",
    "                    else:\n",
    "                        removed_var.append(var_IV_sorted[i])\n",
    "                        \n",
    "var_IV_sorted_2=[i for i in var_IV_sorted if i not in removed_var]\n",
    "print('剩余',len(var_IV_sorted_2),'个变量')\n",
    "print(var_IV_sorted_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2016Q4数据中，逾期坏样本比例28%，我们可以不用\"过抽样\"。本着探讨的精神， 我会用逻辑回归，XGBOOST 这2个模型，未SMOT抽样，SMOTE抽样这2种情况，共训练4个模型；\n",
    "\n",
    "\n",
    "之后这4个模型会在在2017Q1数据中分别加载，看看效果。\n",
    "\n",
    "\n",
    "先看smote抽样方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=data[var_WOE_list]\n",
    "y=data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('采样前')\n",
    "n_sample = y.shape[0]\n",
    "n_pos_sample = y[y==0].shape[0]\n",
    "n_neg_sample = y[y==1].shape[0]\n",
    "print('特征个数：',X.shape[1])\n",
    "print()\n",
    "print('样本个数{}，正常样本{},逾期样本{},逾期样本占{:.0%}'.format(n_sample,n_pos_sample,n_neg_sample,n_neg_sample/n_sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote=SMOTE(random_state=1)\n",
    "X,y=smote.fit_sample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('采样后')\n",
    "n_sample = y.shape[0]\n",
    "n_pos_sample = y[y==0].shape[0]\n",
    "n_neg_sample = y[y==1].shape[0]\n",
    "print('特征个数：',X.shape[1])\n",
    "print()\n",
    "print('样本个数{}，正常样本{},逾期样本{},逾期样本占{:.0%}'.format(n_sample,n_pos_sample,n_neg_sample,n_neg_sample/n_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑回归有个显著性检验，这一步也可以筛选变量：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summary这几个变量都是显著的，下面建模\n",
    "\n",
    "\n",
    "\n",
    "第一个模型是经过smote抽样后的逻辑回归模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr=LR()\n",
    "lr.fit(X_train,y_train)\n",
    "y_train_label=lr.predict(X_train)\n",
    "y_test_label=lr.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('训练集准确率：{:.2%}'.format(accuracy_score(y_train_label,y_train)))\n",
    "print('测试集准确率：{:.2%}'.format(accuracy_score(y_test_label,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们发现统计指标不是很好，别灰心，惊喜在下面！\n",
    "\n",
    "再看看经过smote抽样的xgboost模型：\n",
    "\n",
    "是不是很激动，统计指标辣么高！\n",
    "\n",
    "再看更鸡冻的：红线代表逾期客户的分数分布，蓝线代表正常客户的分数分布。\n",
    "\n",
    "\n",
    "\n",
    "我们发现：哇塞，低分与高分分的好开，直接拒绝低分的，放过高分的，人工审核中间分的，太棒了！\n",
    "\n",
    "但是，它过拟合了。接下来告诉你什么\n",
    "\n",
    "\n",
    "\n",
    "我们再看看未经过smote抽样的数据，分别用逻辑回归和xgboost试试。\n",
    "\n",
    "先看LR："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''逻辑回归'''\n",
    "from sklearn.cross_validation import train_test_split as sp\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "X=data[features_selection]\n",
    "y=data['traget']\n",
    "X_train,X_test,y_train,y_test=sp(X,y,test_size=0.3,random_stated=1)\n",
    "\n",
    "lr=LR()\n",
    "lr.fit(X_train,y_train)\n",
    "y_train_label=lr.predict(X_train)\n",
    "y_test_label=lr.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('训练集准确率：{:.2%}'.format(accuracy_score(y_train_label,y_train)))\n",
    "print('测试集准确率：{:.2%}'.format(accuracy_score(y_test_label,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们会发现，未经过smote抽样的逻辑回归准确率大幅提升，KS和AUC变化不明显。\n",
    "\n",
    "\n",
    "\n",
    "再看XGBOOST："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split as sp\n",
    "X_train,X_test,y_train,y_test=sp(X,y,test_size=0.3,random_stated=1)\n",
    "\n",
    "modelfit(xgb1,X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计指标大幅下降！  但是比逻辑回归略好\n",
    "\n",
    "\n",
    "\n",
    "这4个模型训练好了，我们看下这4个模型在2017年第1季度数据上的表现\n",
    "\n",
    "\n",
    "\n",
    "先加载未经过smote采样的逻辑回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可见：虽然说是不同的数据，但逻辑回归表现的还是比较稳定的\n",
    "\n",
    "\n",
    "\n",
    "再加载经过smote采样的逻辑回归模型我们发现smote采样后的模型，测试准确率低了很多。\n",
    "\n",
    "\n",
    "\n",
    "前辈经验是10%坏样本以上的数据尽量先不用smote采样哦\n",
    "\n",
    "\n",
    "\n",
    "同样的方法加载XGBOOST模型，这里就不赘述了。\n",
    "\n",
    "\n",
    "\n",
    "最后把汇总的统计指标发给大家，怎么分析，仁者见仁智者见智啦。\n",
    "\n",
    "\n",
    "\n",
    "X轴：0表示未smote抽样，load表示加载模型\n",
    "\n",
    "Y轴：统计指标实际值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们发现smote采样后的模型，测试准确率低了很多。\n",
    "\n",
    "\n",
    "\n",
    "前辈经验是10%坏样本以上的数据尽量先不用smote采样哦\n",
    "\n",
    "\n",
    "\n",
    "同样的方法加载XGBOOST模型，这里就不赘述了。\n",
    "\n",
    "\n",
    "\n",
    "最后把汇总的统计指标发给大家，怎么分析，仁者见仁智者见智啦。\n",
    "\n",
    "\n",
    "\n",
    "X轴：0表示未smote抽样，load表示加载模型\n",
    "\n",
    "Y轴：统计指标实际值"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
