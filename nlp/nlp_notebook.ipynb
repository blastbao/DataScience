{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本挖掘学习笔记\n",
    "\n",
    "## 简单的统计\n",
    "\n",
    "先不考虑奖文本转化成向量，对于评论等一些非结构性数据，可以先分词\n",
    "\n",
    "## 工具包\n",
    "\n",
    "1、英语 textblob\n",
    "```cmd\n",
    "pip install -U textblob\n",
    "python -m textblob.download_corpora\n",
    "```\n",
    "2、德语(法语类似)\n",
    "```cmd\n",
    "pip install -U textblob-de\n",
    "python -m textblob.download_corpora\n",
    "```\n",
    "对于分词而言，差异不大。语言带来的差异主要是词性分析、情感分析等\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('das', 30), ('ich', 26), ('die', 24), ('ist', 24), ('und', 21), ('es', 19), ('mit', 18), ('der', 17), ('advance', 15), ('zu', 13)]\n"
     ]
    }
   ],
   "source": [
    "# 非中文分词\n",
    "'''\n",
    "每个词语都是通过空格火标点符号分开，不像中文\n",
    "'''\n",
    "import pandas as pd\n",
    "from textblob_de import TextBlobDE as TextBlob\n",
    "# 导入德国亚马逊评论数据\n",
    "d=pd.read_csv('C:\\\\home\\\\Codinglife\\\\mypython3\\\\pyspider\\\\reviews\\\\data\\\\B007A2K9YS.csv')\n",
    "s=d['review'][0]\n",
    "# 建立模型\n",
    "model=TextBlob(s)\n",
    "model=model.lower()\n",
    "wc=model.word_counts\n",
    "# wc是一个类字典格式的数据，记录着所有的分词频数统计\n",
    "wc1=[(k,wc[k]) for k in wc]\n",
    "wc1=sorted(wc1,key=lambda x:x[1],reverse=True)\n",
    "print(wc1[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用这些数据，理论上我们就可以做词云了。当然这里还有两件事可以做：\n",
    "1. 去除无用词汇，可以找到对应语言的stopwords\n",
    "2. 翻译成英文. 国外可以直接用textblob，国内推荐使用百度翻译API，很简单，申请个APIKEY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 30), ('i', 26), ('the', 24), ('is', 24), ('and', 21), ('it', 19), ('with', 18), ('the', 17), ('advance', 15), ('to', 13), ('the', 12), ('at', 12), ('in', 12), ('also', 12), ('not', 11), ('you', 10), ('of', 10), ('a', 10), ('update', 10), ('is', 9)]\n"
     ]
    }
   ],
   "source": [
    "from bdfanyi import translate\n",
    "wc2=[(translate(k[0],'en','de'),k[1]) for k in wc1]\n",
    "print(wc2[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
